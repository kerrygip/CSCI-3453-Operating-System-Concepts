MAIN MEMORY

BACKGROUND: INSTRUCTION STYLE

	- Instructions are first fetched from memory
		- CPU has access to registers, cache and main memory 
	- Instructions are then decoded and cause operands to be fetched from memory
	- After instructions have been executed on operands, results can be stored in memory
	- Memory unit only sees memory addresses, not how they are generated or what they are for
	- Can ignore how a program generates memory address
	- Successor instructions are then determined 

	- Instructions can be part of OS or user application
		- Instructions run in the background 

	- Program must be brought from disk into memory and placed within process to run
	- Main memory and registers are the only storage the CPU can access directly
	- Memory unit only sees a stream of addresses and read requests
		- or addresses and data and write requests
		- Memory are byte addressable 

BASIC HARDWARE
	- Register built into CPU can access in one CPU clock or less
	- Main memory can take many cycles, causing a stall
		- Because it is accessed by memory bus
		- Can be fixed to add fast memory between CPU and main memory or on CPU chip for fast access
	- Cache sits between main memory and CPU registers
	- Protection of memory required to ensure correct operation 
		

	- Calculate number of bits(m) required to address memory of size (n)
		- m = log(n)/ log2
	- Calculating memory size(n) given number of address bits (m)
		- n = 2^m 

	- To achieve goal of memory management:
		- Keep as many processes in memory to increase overally system performance
		- Keep track of:
			- Which areas are free/used by whom
		- Give memory to which process?
		- Allocation/deallocation
		- Interaction with CPU Scheduling 

BINDING OF INSTRUCTION AND DATA TO MEMORY
	
	- A program resides on a disk as a binary executable file
		- To run, program must be brought to memory and placed within context of a process
		- It becomes eligible for execution on available CPU
		- As process executes, it accesses instructions and data from memory
		- Process terminates and memory is reclaimed for use by other processes 
	- Addresses in source program are generally symbolic 
	- A Compiler binds to symbolic adresses to relocatable addresses
	- Linker or loader binds to relocatable addresses to absolute addresses
	- Address binding of instructions and data to memory addresses can happen at three different stages

	- Compile time: If memory locations known a priori, absolute code can be generated, must recompile
		if starting location changes
		- Addresses are assigned by the compiler
		- Use fixed addresses when the program is ran
		- Only useful for small system that can run one process at a time
	- Load Time: If it is not known at compile time where the process will be in memory, 
		compiler must generate relocatable code
		- Base address is determined when process is loaded into memory at run time

	- Execution Time: If the process can be moved during its execution from one memory segment to 
		another, then binding must be delated until run time 
		- Need hardware support for address maps
		- Base address is determined at execution time and can change after swapping
		- When process is loaded and assigned to a base address, the base address can change to 
			a different value if processes is swapped in and out 

	- Programs on disk, ready to be brought into memory to execute form an input queue
		- Needs support because otherwise, they'll be loaded into address 0000

BASE AND LIMIT REGISTESR
	- A pair of base and limit registers definite the logical address space
		- Limit is number of bytes allocated to the process
		- Information stored in process control block
		- Can only be loaded into OS by special privilege instruction
	- CPU must check every memory address generated in user mode to be sure it is between base
		and limit for that job
		- Only OS can load base and limit registers
			- Allows the OS to change the value of registers but prevents other programs 
			from changing registers contents 
	- Base register holds the smallest legal physical memory address
	- Limit regiser specifies the size of the range 
	- Range = Base Address + Limit - 1
	- Base address = 0, Limit = 2048. Range = 0-2047
	- Base address = 2048, Limit = 255. Range = 2048- 2302
	- Base address = 2303, Limit = 1024 . Range =  2303 - 3326
	
LOGICAL VS PHYSICAL ADDRESS SPACE
	- Concept of a logical address space that is bound to a separate physical address space is central
		to proper memory management
		- Logical address -Generated by CPU
			- Also referred as virtual address
		- Physical address - Address seen by memory unit
	- Logical and physical addresses are the same in compile time and load time address binding schemes
		- Logical(virtual) and physical address differ in execution time address binding scheme
	- Set of all logical addresses generated by a program is a logical address space
	- Set of all physical addresses corresponding to logical address is physical address space
	- Logical and physical address space differ
	- Logical address maps to physical address
		- Done by Memory Management Unit (MMU) 

MEMORY MANAGEMENT UNIT (MMU)
	- Hardware device that at run time, maps virtual address to physical address
	- Many methods possible
		- Consider scheme where value in relocation register is added to every address generated
			by a user process at the time it is sent to memory
			- Base register is now called relocation register
			CPU -(virtual address)-> MMU -(physical address)-> CPU
			- Base -> Relocation process 
	- User program deals with logical address, never sees physical address
		- Execution time binding occurs when reference is made to location in memory
		- Logical address bound to physical address 

SWAPPING
	- Process instructions and the data they operate on must be in memory to be executed
	- Process or portion of a process can be swapped temporarily out of memory to a backing store
		then brought back into memory for continued execution
	- Swapping makes it possible for total physical address space to exceed physical memory of system
		- Increasing degree of multiprogramming in system 

	- Backing store - fast disk, large enough to accomodate copies of all memory images for all users
		- must provide direct access to memory images 
	- Roll out, Roll in - Swapping variant used for priority based scheduling algorithms 
		- Lower priority proceses are swapped out so higher priority process can be loaded and 
		executed
	- Major part of swap time is transfer time. 
	- Total transfer time is directly proportional to amount of memory swapped
	- System maintains a ready queue of ready to run processes which have memory images on disk
	- Does the swapped out process need to swap back into the same physical address?
		- Depends on address binding method
		- Compile time binding
		- Load time binding
		- Execution time binding 

CONTEXT SWITCH TIME INCLUDING SWAPPING
	- If next processes to be put on CPU is not in memory, need to swap out a process and swap in 
		target process
	- Contect switch time can be very high because of this 
	
	ex: 
		- 100 MB process swapping to hard disk with transfer reate of 50MB/sec
		- Swap out time of 2000 ms(2 seconds)
		- Plus swap in of same sized process
		- Total context switch swapping component time of 4000 ms(4 sec)
		- Can reduce if size of memory swapped by how much memory is really beign used
		- Standard swapping not used in modern OS
			- Modified version is common
			- Swap only when free memory is extrememly low

MEMORY MANAGEMENT SCHEME

	- CONTIGUOUS ALLOCATION
		- Main memory must support both OS and user processes
		- Limited Resource
		- Must allocate efficiently
		- Contiguous allocation is one early method
		- Main memory is divided into two partitions
			- Resident OS, usually held in low memory
			- User processes then held in high memory
			- Each process contained in single contiguous seciton of memory 
		- MULTIPLE PARTITION ALLOCATION
			- Degree of multiprogramming limited by number of partitions
			- Variable parition sizes for efficiency 
				- Sized to a given processes's needs
			- Hole: - Block of available memory
				- Holes of various sizes are scattered throughout memory
			- When a process arrives, it is allocated memory from a hole large enough to 
				Accomodate it 
			- Process exiting frees its partition
				- Adjacent free partitions combined
			- Operating system maintains information about 
				- Allocated Partitions
				- Free Partitions (Hole) 

	- DYNAMIC STORAGE ALLOCATION PROBLEM
		- How to satisfy a request of size n from a list of free holes?
			- First fit: Allocate the first hole that is big enough
			- Best Fit: Allocate the smallest hole that is big enough
				- Must search entire list, unless ordered by size
				- Produces smallest lefotover hole
			- Worst Fit: Allocates largest hole
				- Must search entire lilst
				- Prouduces largest leftover fit
		- First and best fit better than worst fit in terms of speed and storage utilization
	- FRAGMENTATION
		- External Fragmentation:	
			- Total memory space exists to satisfy a request, but not contiguous
		- Internal Fragmentation:
			- Allocated memory may be slightly larger than requested memory
			- Size difference is memory internal to a partition, but not being used
		- First fit analysis reveals that given N blocks allocated. 
			- 0.5N Blocks lost to fragmentation
			- 1/3 may be unusable 
		- Reduce external fragmentation by compaction
			- Shuffle memory contents to place all free memory together in one large block
			- Compaction is possibly only if relocation is dynamic and is done at 
				execution time 
PAGING
	- Solution to external fragmentation problem is to permit the logical address space of processes 
		to be more noncontiguous. Thus allowing a process to be allocated to physical memory
		wherever such memory is available
	- Most common memory management technique for computer systems
	- Allows process's physical address space to be non-contiguous
		- Avoids problem of varying sized memory chunks 
	- Avoids external fragmentation and associated need for compaction
	- Process is allocated physical memory whenever the latter is available
	- Implemented through cooperation between OS and computer hardware 

	- Divides physical memory into fixed sized blocks called frames
		- Size is power 2 between 512 bytes and 16 Mbytes
		- Divide logical memory into blocks of same size called pages
		- Backing store likewise split into pages
	- Keeps track of all free frames
	- To run a program of size N pages, need to find N free frams and load program
	- Set up a page table to translate logical to physical addresses
	- Still have internal fragmentation 
	
	- ADDRESS TRANSLATION SCHEME
		- Address generated by CPU is divided into
			- Page Number(p) - Used as index into a page table which contains base address 
			of each page in physical memory
				- Page addres uses m-n bits, giving us 2^)m-n) possible pages 
			- Page Offset(d) - Combined with base address to define the physical memory address
			that is sent to the memory unit
				- For a given logical address space 2^m (m bits are needed for logical 
				address)
				- Displacement uses n bits then page size 2^n

	

		- Logical address size : 32 bits
			- 4 GB of addressable bytes
		- Divide this into pages of size:
			- 4096 bytes (4kb)  -> 4096/log2 = 12 
			- Need to use 12 bites to address displacement
		- 30-12 = 20 bites available to address page number
			- 2^20 pages
		- Number of pages * page size = Total number of available bytes ********


		- Physical address size : 16 bites
			- 64 KB of addressable bytes
		- Divide this intp frames of size:
			- 4096 bytes (4kb)
			- Need to use 12 bits to address displacement
		- 16-12 = 4 bits available to address frame number
			- We can have 2^4 frames 


	- Calculating Internal Fragmentation
		- Page size = 2048 bytes
		- Process Size = 72,766 bytes
		- 35 pages + 1086 bytes
		- Internal fragmentation of 2048 - 1086 = 962 bytes
	
	- Worst case fragmentation = 1 frame - 1 bytes
	- On average fragmentation = 1/2 frame size
	- Small frame sizes desirable?
		- The smaller  the frame the less waste, but the number of increase into pages also increase
			- Therefore also increases memory  
	- System can support multiple page sizes
	- Process view and physical memory now very different
	- By implementation process, can only access its own memory 


IMPLEMENTATION OF PAGE TABLE
	- Page table is kept in main memory
	- Page table base register (PTBR) points to the page table
	- Page table length register (PTLR) indicates size of page table
	- In this scheme, every data/instruction access requires two memory accesses
		- One for the page table and one for data/instruction
	- The two memory access problem can be solved by the use of a special fast lookup hardware cache called
		associative memory or Translation Look-Aside Buffers (TLBs)	

	- Some TLBs store address- space identifiers (ASIDs) in each TLB entry
		- Uniquely identifies each process to provide address space protection for that process
		- Otherwise, need to flush at every context switch
	- TLBs typically small (64 to 1024 entries)
	- On a TLB miss, value is loaded into the TLB for faster access next time
		- Replacement policies must be considered
		- Some entries can be wired down for permanent fast access

EFFECTIVE ACCESS TIME
	- Associate lookup = e time unit
		- Can be < 10% of memory access time
	- Hit ratio = a(alpha)
		- Hit ratio - percentage of times that a page number is found in associative registers
	- Example:
		- a = 80%, e = 20ns for TLB searrch, 100 ns for memory access
		- a = 99%, e = 20ns for TLB searrch, 100 ns for memory access


MEMORY PROTECTION
	- Memory protection implemented by associating protection bit with each frame to indicate if
		read-only or read- write access is allowed
		- Can also add more bits to indicate page execute only and so on
	- Valid-invalid bit attached to each entry in the page table:
		- Valid indicates that the associated page is in the process logical address space 
		and is this a legal page
		- Invalid indicates that the page is not in the process logical address space
		- Any violations result in a trap to  the kernel 

SHARED PAGES
	- Shared code
		- One copy of read only coe shared among processes
		- Similar to multiple threads sharing the same process space
		- Also useful for interprocess communication of sharing read-write pages are allowed
	- Private code and data
		- Each process keeps a separate copy of the code and data
		- The pages for the private code and data can appear anywehre in the logical address space 

STRUCTURE OF THE PAGE TABLE
	- Memory structures for paging can get huge using straight forward methods
		- Consider a 32 bit logical address space as on modern computers
		- Page size of 4 KB(212)
		- Page table would have 1 million entries (232/212)
		- If each entry is 4 bytes -> 4MB of physical address space/ memory for page table alone
			- Memory used to cost a lot
			- Dont want to allocate that contiguously in main memory 

	- HIERARCHICAL PAGE TABLES
		- Break up the logical address space into multiple page tables
		- A Simple technique is a two level page table
		- We then page the page table 

		- TWO LEVEL PAGING 
			- A logical address (32 bit machine with 1000 page size)
				- page number consisting of 22 bites
				- page offset consisting of 10 bits
			- Since the page table is paged, the page number is divided again into
				- 12 bit page number
				- 10 bit page offset 
			- Logical address is as follows:
				page number | page offset
				p1   p2     |  d
				12   10     |  10
				
				- where p1 is an index into the outer page table
				- where p2 is the displacement within the page of inner page table
				- known as forward mapped page table 

	- HASHED PAGE TABLES
		- Common in address spaces > 32 bits
			- Virtual page number is hashed into a page table
				- Page table contains a chain of elements hashing to same location
		- Each elemenet contains (1) the virtual page number
				- (2) the value of mapped page frame
				- (3) a pointer to the next element
		- Virtual page numbers are compared in thsi chain searching for a match
			- if a match is found, the corresponding physical frame is extracted  
		- in a key value pair, value is the frame value 

	- INVERTED PAGE TABLE
		- Rather  than each process having a page table and keeping track of all the logical pages
			we keep track of all the physical pages
		- One entry for each real page of memory
		- Entry consists of the virtual address of the page stored in that real memory location
			- With information about the process that owns that page
		- Decreases memory needed to store each page table, but increases time needed
			- to search the table when a page reference occurs
		- Use hash table to limit the search to one or at most a fwe page table entries
			- TLB can acceslerate access 


















